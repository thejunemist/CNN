{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thejunemist/CNN/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uo5v4GXDZx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8b4d9b7a-5d65-4dd2-87cb-3b94b22dafa4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'cnn/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysZaszrcDvDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "599f8696-84d9-4943-fd2f-bf7d8721f657"
      },
      "source": [
        "  !curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihg2HzFq9FA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "bd599758-0456-4a39-9327-5c6408f56f66"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "def train_batch(_model, _x_tensor, _y_tensor, _target):\n",
        "    _model.zero_grad()\n",
        "    # input should be batch, alphabet, hidden_size\n",
        "    out = _model(_x_tensor)\n",
        "    _loss = _target(out.cuda(), _y_tensor.long())\n",
        "    _loss.backward()\n",
        "    for p in _model.parameters():\n",
        "        if p.grad is not None:\n",
        "            p.data.add_(-LEARNING_RATE, p.grad.data)\n",
        "    torch.cuda.empty_cache()\n",
        "    return out, _loss.item()\n",
        "\n",
        "\n",
        "def evaluate(_model, _x_val, _y_val):\n",
        "    out = _model(_x_val)\n",
        "    out_proba, out_class = torch.max(out, 1)\n",
        "    acc = accuracy_score(_y_val.type(torch.int32).numpy(),\n",
        "                         out_class.cpu().type(torch.int32).numpy())\n",
        "    f1 = f1_score(_y_val.type(torch.int32).numpy(),\n",
        "                  out_class.cpu().type(torch.int32).numpy(), average='weighted')\n",
        "    cr = classification_report(_y_val.type(torch.int32).numpy(),\n",
        "                               out_class.cpu().type(torch.int32).numpy())\n",
        "    return acc, f1, cr\n",
        "Collapse"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f75e030be891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUSE_CUDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhyt5B8WArX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=REG_PARAM) #, momentum=MOMENTUM)\n",
        "    #scheduler = CyclicLR(optimizer)\n",
        "    stopper = EarlyStopping(patience=101, verbose=True, saver=False)\n",
        "    for epoch in range(EPOCHS):\n",
        "        el = 0\n",
        "        model.train()\n",
        "        for batch in train_batched:\n",
        "            #scheduler.batch_step()\n",
        "            x = Variable(batch[0].cuda(),  requires_grad=True)\n",
        "            y = Variable(batch[1].cuda())\n",
        "            preds, loss = train_batch(model, x, y, criterion)\n",
        "            el += loss\n",
        "\n",
        "        model.eval()\n",
        "        for val_batch in valid_set:\n",
        "            x_val = Variable(val_batch[0].cuda())\n",
        "            y_val = Variable(val_batch[1].cuda())\n",
        "            val_out = model(x_val)\n",
        "            val_loss = criterion(val_out.cuda(), y_val.long())\n",
        "        stopper(val_loss, model)\n",
        "\n",
        "        if stopper.early_stop:\n",
        "            print(\"Stopping training at epoch {cur}\".format(cur=epoch))\n",
        "            for test_batch in test_set:\n",
        "                x_test = Variable(test_batch[0].cuda())\n",
        "                y_test = Variable(test_batch[1])\n",
        "                acc, f1, cr = evaluate(model, x_test, y_test)\n",
        "                print('Test set accuracy of {a} and F1 of {f}'.format(a=acc, f=f1))\n",
        "                print(cr)\n",
        "            break\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            for test_batch in test_set:\n",
        "                x_test = Variable(test_batch[0].cuda())\n",
        "                y_test = Variable(test_batch[1])\n",
        "                acc, f1, cr = evaluate(model, x_test, y_test)\n",
        "                print('Test set accuracy of {a} and F1 of {f}'.format(a=acc, f=f1))\n",
        "                print(cr)\n",
        "        print('Epoch {e} had loss {ls}'.format(e=epoch, ls=el))\n",
        "        #lr_list = scheduler.get_lr()\n",
        "    torch.save(model.state_dict(), 'outputs/conv_model.pt')\n",
        "    #print('Final learning rate was {x}'.format(x=lr_list[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}